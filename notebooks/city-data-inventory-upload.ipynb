{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas\n",
    "from tqdm.auto import tqdm\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ldap3 import Server, Connection, ALL, NTLM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import re\n",
    "import json\n",
    "from difflib import SequenceMatcher\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from db_utils import minio_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "secrets = json.load(open(\"/home/jovyan/secrets/secrets.json\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting inventory data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minio_utils.minio_to_file(\n",
    "    filename=\"../tempdata/WIP-Data-Inventory-November-2019.xlsx\",\n",
    "    minio_bucket=\"data-inventory\",\n",
    "    minio_key=secrets[\"minio\"][\"edge\"][\"access\"],\n",
    "    minio_secret=secrets[\"minio\"][\"edge\"][\"secret\"],\n",
    "    data_classification=minio_utils.DataClassification.EDGE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inventory_df = pandas.read_excel(\"../tempdata/WIP-Data-Inventory-November-2019.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minio_utils.dataframe_to_minio(\n",
    "    inventory_df,\n",
    "    minio_bucket=\"data-inventory.raw\",\n",
    "    minio_key=secrets[\"minio\"][\"edge\"][\"access\"],\n",
    "    minio_secret=secrets[\"minio\"][\"edge\"][\"secret\"],\n",
    "    data_classification=minio_utils.DataClassification.EDGE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inventory_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inventory_df['DS Directorate'].str.title().str.strip().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Organisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directorates = {\n",
    "   \"Water And Waste\",\n",
    "   \"Spatial Planning And Environment\",\n",
    "   \"Corporate Services\",\n",
    "   \"Finance\",\n",
    "   \"Economic Opportunities And Asset Management\",\n",
    "   \"Energy And Climate Change\",\n",
    "   \"Community Services And Health\",\n",
    "   \"Transport\", \n",
    "   \"Safety And Security\",\n",
    "   \"Human Settlements\", \n",
    "   \"Urban Management\",\n",
    "   \"Office Of The City Manager\",\n",
    "   \"Under Construction\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckan_api_key = secrets[\"city-ckan\"][\"ckan-api-key\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_action_path_template = 'https://ds3.capetown.gov.za/data-catalogue/api/action/{}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for directorate in directorates:\n",
    "    directorate_slug = directorate.lower().replace(\" \",\"_\")\n",
    "    \n",
    "    resp = requests.post(\n",
    "        api_action_path_template.format('organization_create'),\n",
    "        data={\n",
    "            \"name\": directorate_slug,\n",
    "            \"title\": directorate,\n",
    "            \"description\": f\"Organisation for data sets that are under the stewardship of the {directorate} directorate\"\n",
    "        },\n",
    "        headers={\"X-CKAN-API-Key\": ckan_api_key},\n",
    "    )\n",
    "    \n",
    "    print(directorate, resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for directorate in directorates:\n",
    "    directorate_slug = directorate.lower().replace(\" \",\"_\")\n",
    "    \n",
    "    resp = requests.post(\n",
    "        api_action_path_template.format('organization_purge'),\n",
    "        data={\n",
    "            \"id\": directorate_slug,\n",
    "        },\n",
    "        headers={\"X-CKAN-API-Key\": ckan_api_key},\n",
    "    )\n",
    "    \n",
    "    print(directorate, resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting email addresses\n",
    "With the power of LDAP*!\n",
    "\n",
    "\\*no ADs were harmed in the making of this email list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people = pandas.concat([inventory_df[col] for col in [\"Data Steward (DS)\", \"Data Custodian\", \"Technical Reference\"]]).apply(label_sanitise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From my laptop\n",
    "Still need to get LDAP ports unblocked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.DataFrame(people.unique()).to_csv(\"inventory_people.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inventory_emails = pandas.read_csv(\"inventory_people_with_email.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails_dict = inventory_emails.set_index(0).to_dict()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails_dict[\"Adri Janse Van Rensburg\"] = \"Adri.JansevanRensburg@capetown.gov.za\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How the sausage is made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_df = people[0].str.split(r\"[/\\n\\-\\:]\", expand=True).dropna(how=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# server = Server('capetown.gov.za', get_info=ALL, use_ssl=True) \n",
    "# conn = Connection(\n",
    "#     server, \n",
    "#     user=f\"CAPETOWN\\\\{secrets[\"proxy\"][\"username\"]}\", password=f\"{secrets[\"proxy\"][\"password\"]}\", \n",
    "#     authentication=NTLM, auto_bind=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @functools.lru_cache(1000) \n",
    "# def lookup_email(common_name):\n",
    "#     common_name = common_name.strip() if pandas.notna(common_name) else None\n",
    "#     if common_name is None:\n",
    "#         return None\n",
    "#     time.sleep(0.1)\n",
    "#     try:\n",
    "#         conn.search('DC=capetown,DC=gov,DC=za',f'(&(objectClass=user)(cn={common_name}))', attributes=['displayName', 'mail']) \n",
    "#         email = conn.entries[0][\"mail\"].value \n",
    "#         return email \n",
    "#     except: \n",
    "#         print(f\"Couldn't find for {common_name}\") \n",
    "#         return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_df = pandas.DataFrame()\n",
    "# for col in raw_df.columns:\n",
    "#     result_df.loc[:,col] = raw_df[col].apply(lookup_email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inventory_emails = {name: email for name, email in zip(raw_df.values.flatten(), result_df.values.flatten()) if email is not None}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading inventory into CKAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_char_pattern = re.compile('[^a-z0-9-_]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_pattern = re.compile(\"([a-zA-Z0-9.!#$%&'*+/=?^_`{|}~-]+@[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?(?:\\.[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?)*)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Package (dataset) create [API reference](https://docs.ckan.org/en/2.8/api/#ckan.logic.action.create.package_create)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_field_blacklist = {\n",
    "    'Data Set Description (old)',\n",
    "    'Data Set Purpose',\n",
    "    'Master Data Content Type',\n",
    "    'Person Type Description',\n",
    "    'Location Type Description ', \n",
    "    'Object Type Description',\n",
    "    'Comments',\n",
    "    'Server Name',\n",
    "    'Physical Locations', \n",
    "    'Unnamed: 35', \n",
    "    'Unnamed: 36', \n",
    "    'Unnamed: 37',\n",
    "    'Additional Data Sourcing Method Description (Free Text)  x1, x2, xn',\n",
    "    'DS/TR Contact Information',\n",
    "    'Data Format Description',\n",
    "    'Data Source Name',\n",
    "    'Data Sourcing Method',\n",
    "    'Data Type',\n",
    "    'Event-based frequency description',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http = requests.Session()\n",
    "# for dataset in tqdm(inventory_df.to_dict(orient='records')[:]):\n",
    "#     dataset_slug = label_to_value(dataset['Data Set Alias (Commonly known name)']).strip().lower().replace(\" \",\"-\")\n",
    "#     dataset_slug = re.sub(bad_char_pattern, \"\", dataset_slug,)\n",
    "    \n",
    "#     directorate = str(dataset['DS Directorate']).strip().title()\n",
    "#     directorate_slug = directorate.lower().replace(\" \",\"-\")\n",
    "#     #print(directorate_slug)\n",
    "    \n",
    "#     dataset_metadata = {\n",
    "#         'name': dataset_slug,\n",
    "#         'title': dataset['Data Set Alias (Commonly known name)'],\n",
    "#         'private': False,\n",
    "#         'author': dataset['Data Owner'], \n",
    "#         'maintainer': dataset['Data Steward (DS)'],\n",
    "#         'notes': dataset['Data Set Description'],\n",
    "#         'owner_org': directorate_slug,\n",
    "#         'extras': [\n",
    "#            {'key': column.strip(), 'value': str(dataset[column])}\n",
    "#            for column in inventory_df.columns.values\n",
    "#            if not column in metadata_field_blacklist\n",
    "#         ]\n",
    "#     }\n",
    "#     #print(pprint.pformat(dataset_metadata))\n",
    "    \n",
    "#     #print(dataset['DS/TR Contact Information'])\n",
    "#     contact_details = str(dataset['DS/TR Contact Information']) if pandas.notna(dataset['DS/TR Contact Information']) else \"\"\n",
    "#     contact_email_match = re.match(email_pattern, contact_details)\n",
    "#     if contact_email_match:\n",
    "#         dataset_metadata[\"maintainer_email\"] = contact_email_match.group(0)\n",
    "    \n",
    "#     if directorate in directorates and len(dataset_slug) > 1:\n",
    "#         resp = http.post(\n",
    "#             api_action_path_template.format('package_create'),\n",
    "#             data=json.dumps(dataset_metadata),\n",
    "#             headers={\"X-CKAN-API-Key\": ckan_api_key, 'Content-Type': 'application/json'},   \n",
    "#         )\n",
    "#     elif len(dataset_slug) < 2:\n",
    "#         print(f\"data set '{dataset['Data Set Alias (Commonly known name)']}' is too short\")\n",
    "#     else:\n",
    "#         print(f\"data set '{dataset['Data Set Alias (Commonly known name)']}' in unknown directorate '{directorate}', putting in under maintenance...\")\n",
    "#         directorate = 'Under Maintenence'\n",
    "#         directorate_slug = 'under-maintenence'\n",
    "#         dataset_metadata['owner_org'] = directorate_slug\n",
    "        \n",
    "#         resp = http.post(\n",
    "#             api_action_path_template.format('package_create'),\n",
    "#             data=json.dumps(dataset_metadata),\n",
    "#             headers={\"X-CKAN-API-Key\": ckan_api_key, 'Content-Type': 'application/json'},   \n",
    "#         )\n",
    "    \n",
    "#     #print(dataset_slug, resp)\n",
    "#     #print(\"\\n\")\n",
    "#     #print(resp.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inventory_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_to_value(label):\n",
    "    sanitised_string = (\n",
    "        str(label).strip()\n",
    "                  .lower()\n",
    "                  .replace(\" \", \"_\")\n",
    "    )\n",
    "\n",
    "    pattern = re.compile(r'\\W')\n",
    "    sanitised_string = re.sub(\n",
    "        pattern, \"\",\n",
    "        sanitised_string\n",
    "    )\n",
    "\n",
    "    return sanitised_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_sanitise(label):\n",
    "    sanitised_string = (\n",
    "        str(label).strip()\n",
    "                  .replace(\"^\\s$\", \"\")\n",
    "        if pandas.notna(label)\n",
    "        else None\n",
    "    )\n",
    "    sanitised_string = sanitised_string if sanitised_string != \"\" else None\n",
    "    \n",
    "    return sanitised_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_pattern = re.compile(r'[/\\n\\-\\:]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "http = requests.Session()\n",
    "i = 0\n",
    "for dataset in tqdm(inventory_df.to_dict(orient='records')[:]):\n",
    "    # Applying string sanitising\n",
    "    dataset_sanitised = {\n",
    "        key: label_sanitise(value)\n",
    "        for key, value in dataset.items()\n",
    "    }\n",
    "    dataset_values = {\n",
    "        key: label_to_value(value)\n",
    "        for key, value in dataset.items()\n",
    "    }\n",
    "    dataset_slug = dataset_values['Data Set Alias (Commonly known name)'][:100]\n",
    "    \n",
    "    # Choices validation\n",
    "    dataset_values[\"Update Frequency\"] = (\n",
    "        dataset_values[\"Update Frequency\"]\n",
    "        if dataset_values[\"Update Frequency\"] in [\"historical\", \"event-based\"]\n",
    "        else None\n",
    "    )\n",
    "    dataset_values[\"Data Access Rights\"] = (\n",
    "        dataset_values['Data Access Rights']\n",
    "        if dataset_values['Data Access Rights'] in [\"open_public\", \n",
    "                                                    \"internal_open\", \n",
    "                                                    \"internal_restricted\",\n",
    "                                                    \"secret\"]\n",
    "        else None\n",
    "    )\n",
    "    \n",
    "    # Forming Org values\n",
    "    directorate = str(dataset['DS Directorate']).strip().title()\n",
    "    under_construction = True if directorate not in directorates else False\n",
    "    \n",
    "    directorate_slug = label_to_value(directorate) if not under_construction else directorate\n",
    "    department_slug = (\n",
    "        \"_\".join([directorate_slug, dataset_values['DS Department']])\n",
    "        if pandas.notna(dataset['DS Department']) and not under_construction\n",
    "        else None\n",
    "    )\n",
    "    branch_slug = (\n",
    "        \"_\".join([department_slug, dataset_values['DS Branch']])\n",
    "        if pandas.notna(dataset['DS Branch']) and not under_construction\n",
    "        else None\n",
    "    )\n",
    "    \n",
    "    dataset_metadata = {\n",
    "        'name': dataset_slug,\n",
    "        'title': dataset_sanitised['Data Set Alias (Commonly known name)'],\n",
    "        'notes': dataset_sanitised['Data Set Description'],\n",
    "        \"data_quality\": dataset_sanitised['Data Quality'],\n",
    "        \"update_frequency\": dataset_values[\"Update Frequency\"],\n",
    "        \"data_access_rights\": dataset_values[\"Data Access Rights\"],\n",
    "        \"restricted_reason\": dataset_sanitised['Restricted Reason'],\n",
    "        \"data_format\": dataset_sanitised['Data File Format'],\n",
    "        'maintainer': dataset_sanitised['Data Steward (DS)'],\n",
    "        'dstr_branch': branch_slug,\n",
    "        'dstr_department': department_slug,\n",
    "        'owner_org': directorate_slug,\n",
    "        'data_contact_': dataset_sanitised['Technical Reference'],\n",
    "        'publisher': dataset_sanitised['Data Custodian'],\n",
    "        'host_system_id': dataset_values[\"System / Application Name\"],\n",
    "        'spatial_coverage': \"na\",\n",
    "        'temporal_coverage': \"false\",\n",
    "        #'temporal_coverage_start': '',\n",
    "        #'temporal_coverage_end': ''\n",
    "        'private': False,\n",
    "    }\n",
    "    # Adding contact details if present\n",
    "    contact_details = label_sanitise(dataset['DS/TR Contact Information'])\n",
    "    if contact_details is not None:\n",
    "        contact_email_match = email_pattern.match(contact_details)\n",
    "        if contact_email_match:\n",
    "            dataset_metadata[\"maintainer_email\"] = contact_email_match.group(0)\n",
    "        \n",
    "    # We tried what was in the spreadsheet, now to see what else we may have...\n",
    "    for email_field, metadata_field in [(\"Data Steward (DS)\", \"maintainer_email\"), \n",
    "                                        (\"Data Custodian\", \"publisher_email\"), \n",
    "                                        (\"Technical Reference\", \"data_contact_email\")]:\n",
    "        if dataset_sanitised[email_field] is not None:\n",
    "            field_values = split_pattern.split(dataset_sanitised[email_field])\n",
    "            email_lookups = [emails_dict[name] for name in field_values if name in emails_dict]\n",
    "            if len(email_lookups) > 0:\n",
    "                #print(dataset_sanitised['Data Set Alias (Commonly known name)'], email_field, \",\".join(email_lookups))\n",
    "                email_string = \",\".join(email_lookups)\n",
    "                dataset_metadata[metadata_field] = email_string\n",
    "    \n",
    "    under_construction = False\n",
    "    under_construction_set = {\"name\", \"title\", \"maintainer\"}\n",
    "    fix_dict = {}\n",
    "    \n",
    "    # Removing null values\n",
    "    null_values = [key for key, val in dataset_metadata.items() if pandas.isna(val)]\n",
    "    for null_key in null_values:\n",
    "        del dataset_metadata[null_key]\n",
    "        if null_key in under_construction_set:\n",
    "            #print(\"Setting under construction because '{}'\".format(null_key))\n",
    "            under_construction = True\n",
    "        fix_dict[null_key] = \"Missing Value\"\n",
    "        \n",
    "        \n",
    "    # Required values to be set to NA\n",
    "    for key in [\n",
    "        #\"data_set_description\",\n",
    "        \"notes\",\n",
    "        \"data_quality\",\n",
    "        \"data_format\",\n",
    "        'dstr_branch', \n",
    "        'dstr_department', \n",
    "        'data_contact_', \n",
    "        'publisher']:\n",
    "        if key not in dataset_metadata:\n",
    "            dataset_metadata[key] = \"NA\"\n",
    "        \n",
    "    #print(pprint.pformat(dataset_metadata))\n",
    "          \n",
    "    if len(dataset_slug) < 2:\n",
    "        print(f\"data set '{dataset['Data Set Alias (Commonly known name)']}' is too short\")\n",
    "        \n",
    "    else:\n",
    "        header_used = False\n",
    "        while True:\n",
    "            if under_construction:\n",
    "                #print(f\"data set '{dataset['Data Set Alias (Commonly known name)']}' in Under Construction\")\n",
    "                directorate = 'Under Construction'\n",
    "                directorate_slug = 'under_construction'\n",
    "                dataset_metadata['owner_org'] = directorate_slug\n",
    "                \n",
    "            if len(fix_dict):\n",
    "                reason_str = \"\\n\".join([\n",
    "                    \"* `{}` - {}\".format(field, reason) \n",
    "                    for field, reason in fix_dict.items()\n",
    "                ])\n",
    "                \n",
    "                # Clearing the dict\n",
    "                for k in list(fix_dict.keys()):\n",
    "                    del fix_dict[k]\n",
    "                \n",
    "                dataset_metadata[\"notes\"] = (\n",
    "                    dataset_metadata[\"notes\"]\n",
    "                    + (\"\\n## **Metadata that needs to be fixed**\\n\" if not header_used else \"\\n\")\n",
    "                    + reason_str\n",
    "                )\n",
    "                header_used = True\n",
    "            \n",
    "            resp = http.post(\n",
    "                api_action_path_template.format('package_create'),\n",
    "                data=json.dumps(dataset_metadata),\n",
    "                headers={\"X-CKAN-API-Key\": ckan_api_key, 'Content-Type': 'application/json'},   \n",
    "            )\n",
    "            \n",
    "            #print(resp.text)\n",
    "            if resp.ok:\n",
    "                break\n",
    "            elif \"That URL is already in use.\" in resp.text:\n",
    "                break\n",
    "            elif resp.json()['error']['__type'] == 'Validation Error':\n",
    "                under_construction = True\n",
    "                fix_dict = {\n",
    "                    k: \",\".join(v)\n",
    "                    for k,v in resp.json()['error'].items()\n",
    "                    if k != \"__type\"\n",
    "                }\n",
    "            elif resp.json()['error']['__type'] == 'Internal Server Error':\n",
    "                print(\"**INTERNAL SERVER ERROR**\")\n",
    "                print(i, dataset_slug, resp)\n",
    "                break\n",
    "    \n",
    "    #print(i, dataset_slug, resp)\n",
    "    #print(resp.json())\n",
    "    #print(\"\\n\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "http = requests.Session()\n",
    "for dataset in tqdm(inventory_df.to_dict(orient='records')[:10]):\n",
    "    dataset_slug = label_to_value(dataset['Data Set Alias (Commonly known name)'])[:100]\n",
    "    \n",
    "    resp = http.post(\n",
    "        api_action_path_template.format('dataset_purge'),\n",
    "        data={\"id\": dataset_slug},\n",
    "        headers={\"X-CKAN-API-Key\": ckan_api_key},\n",
    "    )\n",
    "    \n",
    "    print(dataset_slug, resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MPortal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_proxy = f\"http://{secrets['proxy']['username']}:{secrets['proxy']['password']}@internet.capetown.gov.za:8080/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mportal_feature_list_request = requests.get(\n",
    "    \"http://mportal.capetown.gov.za/agsint/rest/services/Single_Layers?f=pjson\",\n",
    "    proxies={\"http\": city_proxy,\"https\": city_proxy}\n",
    ")\n",
    "mportal_feature_dict = {\n",
    "    service_dict['name'].split(\"/\")[-1].lower(): service_dict['name']\n",
    "    for service_dict in mportal_feature_list_request.json()['services']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "http = requests.Session()\n",
    "mportal_template = \"http://mportal.capetown.gov.za/agsint/rest/services/{}/MapServer\"\n",
    "for dataset in tqdm(inventory_df.to_dict(orient='records')[:]):\n",
    "    dataset_title = label_to_value(dataset['Data Set Alias (Commonly known name)'])\n",
    "    \n",
    "    matches = []\n",
    "    if dataset_title in mportal_feature_dict:\n",
    "        matches += [dataset_title]\n",
    "    \n",
    "    for entry in mportal_feature_dict:\n",
    "        match_ratio = SequenceMatcher(None, dataset_title, entry).ratio() \n",
    "        if 0.7 <= match_ratio < 1.0:\n",
    "            matches += [entry]\n",
    "            \n",
    "    if len(matches) > 0:\n",
    "        print(f'\"{dataset_title}\" has matches: {\",\".join(matches)}')\n",
    "    \n",
    "    dataset_slug = label_to_value(dataset['Data Set Alias (Commonly known name)'])[:100]\n",
    "    for match in matches:\n",
    "        resource_url = mportal_template.format(mportal_feature_dict[match])\n",
    "        \n",
    "        resource_metadata = {\n",
    "            'package_id': dataset_slug,\n",
    "            'url': resource_url,\n",
    "            'resource_type': 'api',\n",
    "            'format': 'MPortal Link',\n",
    "            'name': f'MPortal Layer \"{mportal_feature_dict[match].replace(\"_\", \" \")}\"',\n",
    "        }\n",
    "        \n",
    "        resp = http.post(\n",
    "            api_action_path_template.format('resource_create'),\n",
    "            data=json.dumps(resource_metadata),\n",
    "            headers={\"X-CKAN-API-Key\": ckan_api_key, 'Content-Type': 'application/json'},\n",
    "            \n",
    "        )\n",
    "        #print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "http = requests.Session()\n",
    "\n",
    "batch_size = 1000\n",
    "for i in range(10):\n",
    "    resp = http.post(\n",
    "        'https://ds3.capetown.gov.za/data-catalogue/api/action/current_package_list_with_resources',\n",
    "        data=json.dumps({'limit': batch_size, 'offset': i*batch_size}),\n",
    "        headers={\"X-CKAN-API-Key\": ckan_api_key, 'Content-Type': 'application/json'}, \n",
    "    )\n",
    "\n",
    "    for dataset in tqdm(resp.json()['result']):\n",
    "        for resource in dataset['resources']:\n",
    "            if 'MPortal Layer' in resource['name']:\n",
    "                #print(f\"Deleting resource from '{dataset['name']}'...\")\n",
    "                resp = http.post(\n",
    "                    api_action_path_template.format('resource_delete'),\n",
    "                    data=json.dumps({\"id\": resource['id'], \"package_id\": dataset['id']}),\n",
    "                    headers={\"X-CKAN-API-Key\": ckan_api_key, 'Content-Type': 'application/json'},\n",
    "                )\n",
    "                \n",
    "                #print(resp.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open Data Portal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odp_feature_list_request = requests.get(\n",
    "    \"https://citymaps.capetown.gov.za/agsext1/rest/services/Theme_Based/Open_Data_Service/MapServer/?f=pjson\",\n",
    "    proxies={\"http\": city_proxy,\"https\": city_proxy}\n",
    ")\n",
    "odp_feature_dict = {\n",
    "    service_dict['name']: service_dict['name'].lower().replace(\" \",\"-\").replace(\"---\",\"-\")\n",
    "    for service_dict in odp_feature_list_request.json()['layers']\n",
    "    if service_dict['minScale'] != 0 and service_dict['maxScale'] != 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "http = requests.Session()\n",
    "mportal_template = \"https://odp-cctegis.opendata.arcgis.com/datasets/{}\"\n",
    "for dataset in tqdm(inventory_df.to_dict(orient='records')[:]):\n",
    "    dataset_title = label_sanitise(dataset['Data Set Alias (Commonly known name)'])\n",
    "    if dataset_title is not None:\n",
    "        matches = [\n",
    "            entry\n",
    "            for entry in odp_feature_dict\n",
    "            if 0.7 <= SequenceMatcher(None, dataset_title, entry).ratio() <= 1.0\n",
    "        ]\n",
    "\n",
    "        if len(matches) > 0:\n",
    "            print(f'\"{dataset_title}\" has matches: {\", \".join(matches)}')\n",
    "    \n",
    "        for match in matches:\n",
    "            resource_url = mportal_template.format(odp_feature_dict[match])\n",
    "            #print(f'\"{dataset_title}\" is present at \"{resource_url}\", creating resource...')\n",
    "\n",
    "            dataset_slug = label_to_value(dataset['Data Set Alias (Commonly known name)'])[:100]\n",
    "\n",
    "            resource_metadata = {\n",
    "                'package_id': dataset_slug,\n",
    "                'url': resource_url,\n",
    "                'resource_type': 'api',\n",
    "                'format': 'ODP Link',\n",
    "                'name': f'Open Data Portal data set \"{match}\"',\n",
    "            }\n",
    "\n",
    "            #print(resource_metadata['url'])\n",
    "\n",
    "            resp = http.post(\n",
    "                api_action_path_template.format('resource_create'),\n",
    "                data=json.dumps(resource_metadata),\n",
    "                headers={\"X-CKAN-API-Key\": ckan_api_key, 'Content-Type': 'application/json'},\n",
    "\n",
    "            )\n",
    "            #print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "http = requests.Session()\n",
    "\n",
    "batch_size = 1000\n",
    "for i in range(10):\n",
    "    resp = http.post(\n",
    "        'https://ds3.capetown.gov.za/data-catalogue/api/action/current_package_list_with_resources',\n",
    "        data=json.dumps({'limit': batch_size, 'offset': i*batch_size}),\n",
    "        headers={\"X-CKAN-API-Key\": ckan_api_key, 'Content-Type': 'application/json'}, \n",
    "    )\n",
    "\n",
    "    for dataset in tqdm(resp.json()['result']):\n",
    "        for resource in dataset['resources']:\n",
    "            if 'Open Data Portal data set' in resource['name']:\n",
    "                #print(f\"Deleting resource from '{dataset['name']}'...\")\n",
    "                resp = http.post(\n",
    "                    'https://ds3.capetown.gov.za/data-catalogue/api/action/resource_delete',\n",
    "                    data=json.dumps({\"id\": resource['id'], \"package_id\": dataset['id']}),\n",
    "                    headers={\"X-CKAN-API-Key\": ckan_api_key, 'Content-Type': 'application/json'},\n",
    "                )\n",
    "                \n",
    "                #print(resp.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
